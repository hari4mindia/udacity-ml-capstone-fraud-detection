{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d6cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit Card Fraud Detection - EDA & Preprocessing\n",
    "\n",
    "# Instructions:\n",
    "# 1) Set REGION/BUCKET/PREFIX below\n",
    "# 2) Place creditcard.csv in Studio or S3, then run the cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5155da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"<YOUR_AWS_REGION>\"\n",
    "BUCKET = \"<YOUR_S3_BUCKET_NAME>\"\n",
    "PREFIX = \"fraud\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897e3c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, os, io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "session = boto3.session.Session(region_name=REGION)\n",
    "s3 = session.client(\"s3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe027d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from local file system in Studio (upload via left file browser) OR from S3\n",
    "# Option A: local\n",
    "local_path = \"../data/creditcard.csv\"\n",
    "if os.path.exists(local_path):\n",
    "    df = pd.read_csv(local_path)\n",
    "else:\n",
    "    # Option B: from S3\n",
    "    obj = s3.get_object(Bucket=BUCKET, Key=f\"{PREFIX}/data/raw/creditcard.csv\")\n",
    "    df = pd.read_csv(io.BytesIO(obj[\"Body\"].read()))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cc1046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic stats and class balance\n",
    "print(df.shape)\n",
    "print(df.isna().sum().sum(), \"missing values total\")\n",
    "print(df['Class'].value_counts())\n",
    "df['Class'].value_counts().plot(kind='bar')\n",
    "plt.title('Class Distribution (0=non-fraud, 1=fraud)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea8311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Amount and Time, keep PCA features V1..V28 as-is\n",
    "scaler = RobustScaler()\n",
    "df[['Time', 'Amount']] = scaler.fit_transform(df[['Time','Amount']])\n",
    "\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "Xtr, Xtmp, ytr, ytmp = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "Xval, Xte,  yval, yte = train_test_split(Xtmp, ytmp, test_size=0.5, stratify=ytmp, random_state=42)\n",
    "\n",
    "train = pd.concat([Xtr, ytr], axis=1)\n",
    "val   = pd.concat([Xval, yval], axis=1)\n",
    "test  = pd.concat([Xte, yte], axis=1)\n",
    "\n",
    "train.to_csv(\"train.csv\", index=False)\n",
    "val.to_csv(\"val.csv\", index=False)\n",
    "test.to_csv(\"test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0fc84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload splits to S3\n",
    "for name in [\"train.csv\",\"val.csv\",\"test.csv\"]:\n",
    "    s3.upload_file(Filename=name, Bucket=BUCKET, Key=f\"{PREFIX}/data/processed/{name}\")\n",
    "print(\"Uploaded splits to S3\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
